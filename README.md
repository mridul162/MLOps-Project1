# ğŸš— Endâ€‘toâ€‘End MLOps Project (Productionâ€‘Ready)

> **A complete, industryâ€‘grade MLOps pipeline** demonstrating how realâ€‘world Machine Learning systems are designed, built, deployed, monitored, and continuously delivered using modern tools and cloud infrastructure.

This project is intentionally designed to **impress recruiters, reviewers, and hiring managers** by showcasing **engineering depth**, **cloud readiness**, and **best MLOps practices**.

---

## âœ¨ Key Highlights

âœ… Modular & scalable project structure  
âœ… MongoDB Atlas for cloud data ingestion  
âœ… Robust logging & exception handling  
âœ… Configâ€‘driven data validation & transformation  
âœ… Model training, evaluation & versioning  
âœ… AWS S3â€“based model registry  
âœ… Dockerized ML application  
âœ… CI/CD with GitHub Actions  
âœ… Selfâ€‘hosted runner on AWS EC2  
âœ… Productionâ€‘ready prediction pipeline

---

## ğŸ§  Tech Stack

| Category | Tools |
|-------|------|
| Language | Python 3.10 |
| Data | MongoDB Atlas |
| ML | Scikitâ€‘learn |
| MLOps | Custom pipelines, YAML configs |
| Cloud | AWS (IAM, S3, ECR, EC2) |
| Containerization | Docker |
| CI/CD | GitHub Actions |
| Deployment | EC2 (Selfâ€‘hosted runner) |

---

## ğŸ“ Project Structure (High Level)

```
â”œâ”€â”€ app.py
â”œâ”€â”€ demo.py
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ constants/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ configuration/
â”‚   â”œâ”€â”€ data_access/
â”‚   â”œâ”€â”€ entity/
â”‚   â”œâ”€â”€ aws_storage/
â”‚   â”œâ”€â”€ utils/
â”‚   â””â”€â”€ pipeline/
â”œâ”€â”€ notebook/
â”œâ”€â”€ static/
â”œâ”€â”€ templates/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .github/workflows/aws.yaml
â””â”€â”€ README.md
```

---

## âš™ï¸ Environment & Project Setup

### 1ï¸âƒ£ Project Template
```bash
python template.py
```

### 2ï¸âƒ£ Local Package Management
- Configured **setup.py** and **pyproject.toml**
- Enables reusable, importable local modules

ğŸ“˜ *Reference:* `crashcourse.txt`

### 3ï¸âƒ£ Virtual Environment
```bash
conda create -n vehicle python=3.10 -y
conda activate vehicle
pip install -r requirements.txt
```

### 4ï¸âƒ£ Verify Installation
```bash
pip list
```

---

## ğŸƒ MongoDB Atlas (Cloud Data Layer)

### Setup Steps
- Create MongoDB Atlas project
- Deploy **M0 Free Cluster**
- Create DB user & credentials
- Allow network access: `0.0.0.0/0`
- Obtain Python connection string

### Data Ingestion
- Dataset loaded via Jupyter Notebook
- Stored as **keyâ€‘value documents**
- Verified via Atlas UI

```bash
export MONGODB_URL="mongodb+srv://<username>:<password>@..."
```

---

## ğŸªµ Logging & ğŸš¨ Exception Handling

- Centralized logging system
- Custom exception class
- Tested via `demo.py`
- Enables easy debugging & traceability

---

## ğŸ“Š EDA & Feature Engineering

- Dedicated Jupyter notebooks
- Data understanding & feature preparation
- Clean separation from production code

---

## ğŸ”„ Data Ingestion Pipeline

- MongoDB connection abstraction
- Configâ€‘driven ingestion
- Artifactâ€‘based outputs
- Fully modular pipeline design

Triggered via:
```bash
python demo.py
```

---

## ğŸ§ª Data Validation

- Schemaâ€‘based validation (`schema.yaml`)
- Ensures:
  - Column presence
  - Data types
  - Drift detection readiness

---

## ğŸ”§ Data Transformation

- Feature scaling & preprocessing
- Reusable estimator architecture
- Clean separation of concerns

---

## ğŸ¤– Model Training

- Scikitâ€‘learn estimators
- Configurable hyperparameters
- Trained model artifacts

---

## ğŸ“ˆ Model Evaluation & Registry (AWS S3)

### AWS Setup
- IAM user & access keys
- S3 bucket for model registry

```python
MODEL_BUCKET_NAME = "my-model-mlopsproj162"
MODEL_PUSHER_S3_KEY = "model-registry"
```

### Features
- Model version comparison
- Thresholdâ€‘based promotion
- Previous best model retrieval

---

## ğŸš€ Prediction Pipeline

- Flaskâ€‘based API
- Modular prediction flow
- `/predict` and `/training` routes
- Productionâ€‘ready serving logic

---

## ğŸ³ Dockerization

- Lightweight Docker image
- `.dockerignore` optimization
- Fully reproducible builds

---

## ğŸ” CI/CD with GitHub Actions

### Pipeline Stages
1. Code checkout
2. Docker build
3. Push image to **Amazon ECR**
4. Deploy on **EC2 selfâ€‘hosted runner**

### GitHub Secrets
```
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY
AWS_DEFAULT_REGION
ECR_REPO
```

---

## â˜ï¸ Deployment (AWS EC2)

- Ubuntu 24.04 EC2 instance
- Docker installed
- GitHub selfâ€‘hosted runner
- Port **5000** exposed

Access App:
```
http://<EC2_PUBLIC_IP>:5000
```

---

## ğŸ¯ Why This Project Stands Out

âœ” Shows **real production ML lifecycle**  
âœ” Demonstrates **cloud + DevOps + ML** integration  
âœ” Emphasizes **clean architecture & scalability**  
âœ” Mirrors **industry MLOps workflows**  
âœ” Recruiterâ€‘friendly & enterpriseâ€‘ready

---

## ğŸ“Œ Final Note

This project is not just about training a model â€” itâ€™s about **engineering an ML system that survives in production**.

If you are a recruiter or reviewer: **this repository reflects handsâ€‘on, endâ€‘toâ€‘end MLOps capability.** ğŸš€
